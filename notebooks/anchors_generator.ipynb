{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32ba8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov5_utils.utils.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d8642f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov5_utils.utils.general import colorstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a70f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dir=\"/media/asad/ADAS_CV/datasets_Vegs/tomatoes/dataset_v4/tomatoes_dataset_yolo/train_tomatoe_small.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca88695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd19171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d5f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImagesAndLabels2(Dataset):  # for training/testing\n",
    "    def __init__(self, path, img_size=640, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,\n",
    "                 cache_images=False, single_cls=False, stride=32, pad=0.0, prefix=''):\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.hyp = hyp\n",
    "        self.image_weights = image_weights\n",
    "        self.rect = False if image_weights else rect\n",
    "        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)\n",
    "        self.mosaic_border = [-img_size // 2, -img_size // 2]\n",
    "        self.stride = stride\n",
    "        self.path = path\n",
    "        self.albumentations = Albumentations() if augment else None\n",
    "\n",
    "        try:\n",
    "            f = []  # image files\n",
    "            for p in path if isinstance(path, list) else [path]:\n",
    "                p = Path(p)  # os-agnostic\n",
    "                if p.is_dir():  # dir\n",
    "                    f += glob.glob(str(p / '**' / '*.*'), recursive=True)\n",
    "                    # f = list(p.rglob('**/*.*'))  # pathlib\n",
    "                elif p.is_file():  # file\n",
    "                    with open(p, 'r') as t:\n",
    "                        t = t.read().strip().splitlines()\n",
    "                        parent = str(p.parent) + os.sep\n",
    "                        f += [x.replace('./', parent) if x.startswith('./') else x for x in t]  # local to global path\n",
    "                        # f += [p.parent / x.lstrip(os.sep) for x in t]  # local to global path (pathlib)\n",
    "                else:\n",
    "                    raise Exception(f'{prefix}{p} does not exist')\n",
    "            self.img_files = sorted([x.replace('/', os.sep) for x in f if x.split('.')[-1].lower() in IMG_FORMATS])\n",
    "            # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in img_formats])  # pathlib\n",
    "            assert self.img_files, f'{prefix}No images found'\n",
    "        except Exception as e:\n",
    "            raise Exception(f'{prefix}Error loading data from {path}: {e}\\nSee {HELP_URL}')\n",
    "\n",
    "        # Check cache\n",
    "        self.label_files = img2label_paths(self.img_files)  # labels\n",
    "        cache_path = (p if p.is_file() else Path(self.label_files[0]).parent).with_suffix('.cache')\n",
    "        try:\n",
    "            cache, exists = np.load(cache_path, allow_pickle=True).item(), True  # load dict\n",
    "            assert cache['version'] == 0.4 and cache['hash'] == get_hash(self.label_files + self.img_files)\n",
    "        except:\n",
    "            cache, exists = self.cache_labels(cache_path, prefix), False  # cache\n",
    "\n",
    "        # Display cache\n",
    "        nf, nm, ne, nc, n = cache.pop('results')  # found, missing, empty, corrupted, total\n",
    "        if exists:\n",
    "            d = f\"Scanning '{cache_path}' images and labels... {nf} found, {nm} missing, {ne} empty, {nc} corrupted\"\n",
    "            tqdm(None, desc=prefix + d, total=n, initial=n)  # display cache results\n",
    "            if cache['msgs']:\n",
    "                logging.info('\\n'.join(cache['msgs']))  # display warnings\n",
    "        assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {HELP_URL}'\n",
    "\n",
    "        # Read cache\n",
    "        [cache.pop(k) for k in ('hash', 'version', 'msgs')]  # remove items\n",
    "        labels, shapes, self.segments = zip(*cache.values())\n",
    "        self.labels = list(labels)\n",
    "        self.shapes = np.array(shapes, dtype=np.float64)\n",
    "        self.img_files = list(cache.keys())  # update\n",
    "        self.label_files = img2label_paths(cache.keys())  # update\n",
    "        if single_cls:\n",
    "            for x in self.labels:\n",
    "                x[:, 0] = 0\n",
    "\n",
    "        n = len(shapes)  # number of images\n",
    "        bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index\n",
    "        nb = bi[-1] + 1  # number of batches\n",
    "        self.batch = bi  # batch index of image\n",
    "        self.n = n\n",
    "        self.indices = range(n)\n",
    "        print(f\"Labels are {self.labels}\")\n",
    "        print(f\"Shapes are {self.shapes}\")\n",
    "        print(f\"Rect is {self.rect}\")\n",
    "\n",
    "        # Rectangular Training\n",
    "        if self.rect:\n",
    "            # Sort by aspect ratio\n",
    "            s = self.shapes  # wh\n",
    "            ar = s[:, 1] / s[:, 0]  # aspect ratio\n",
    "            irect = ar.argsort()\n",
    "            self.img_files = [self.img_files[i] for i in irect]\n",
    "            self.label_files = [self.label_files[i] for i in irect]\n",
    "            self.labels = [self.labels[i] for i in irect]\n",
    "            self.shapes = s[irect]  # wh\n",
    "            ar = ar[irect]\n",
    "\n",
    "            # Set training image shapes\n",
    "            shapes = [[1, 1]] * nb\n",
    "            for i in range(nb):\n",
    "                ari = ar[bi == i]\n",
    "                mini, maxi = ari.min(), ari.max()\n",
    "                if maxi < 1:\n",
    "                    shapes[i] = [maxi, 1]\n",
    "                elif mini > 1:\n",
    "                    shapes[i] = [1, 1 / mini]\n",
    "\n",
    "            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(np.int) * stride\n",
    "\n",
    "        # Cache images into memory for faster training (WARNING: large datasets may exceed system RAM)\n",
    "        self.imgs, self.img_npy = [None] * n, [None] * n\n",
    "        if cache_images:\n",
    "            if cache_images == 'disk':\n",
    "                self.im_cache_dir = Path(Path(self.img_files[0]).parent.as_posix() + '_npy')\n",
    "                self.img_npy = [self.im_cache_dir / Path(f).with_suffix('.npy').name for f in self.img_files]\n",
    "                self.im_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "            gb = 0  # Gigabytes of cached images\n",
    "            self.img_hw0, self.img_hw = [None] * n, [None] * n\n",
    "            results = ThreadPool(NUM_THREADS).imap(lambda x: load_image(*x), zip(repeat(self), range(n)))\n",
    "            pbar = tqdm(enumerate(results), total=n)\n",
    "            for i, x in pbar:\n",
    "                if cache_images == 'disk':\n",
    "                    if not self.img_npy[i].exists():\n",
    "                        np.save(self.img_npy[i].as_posix(), x[0])\n",
    "                    gb += self.img_npy[i].stat().st_size\n",
    "                else:\n",
    "                    self.imgs[i], self.img_hw0[i], self.img_hw[i] = x  # im, hw_orig, hw_resized = load_image(self, i)\n",
    "                    gb += self.imgs[i].nbytes\n",
    "                pbar.desc = f'{prefix}Caching images ({gb / 1E9:.1f}GB {cache_images})'\n",
    "            pbar.close()\n",
    "\n",
    "    def cache_labels(self, path=Path('./labels.cache'), prefix=''):\n",
    "        # Cache dataset labels, check images and read shapes\n",
    "        x = {}  # dict\n",
    "        nm, nf, ne, nc, msgs = 0, 0, 0, 0, []  # number missing, found, empty, corrupt, messages\n",
    "        desc = f\"{prefix}Scanning '{path.parent / path.stem}' images and labels...\"\n",
    "        with Pool(NUM_THREADS) as pool:\n",
    "            pbar = tqdm(pool.imap_unordered(verify_image_label, zip(self.img_files, self.label_files, repeat(prefix))),\n",
    "                        desc=desc, total=len(self.img_files))\n",
    "            for im_file, l, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:\n",
    "                nm += nm_f\n",
    "                nf += nf_f\n",
    "                ne += ne_f\n",
    "                nc += nc_f\n",
    "                if im_file:\n",
    "                    x[im_file] = [l, shape, segments]\n",
    "                if msg:\n",
    "                    msgs.append(msg)\n",
    "                pbar.desc = f\"{desc}{nf} found, {nm} missing, {ne} empty, {nc} corrupted\"\n",
    "\n",
    "        pbar.close()\n",
    "        if msgs:\n",
    "            logging.info('\\n'.join(msgs))\n",
    "        if nf == 0:\n",
    "            logging.info(f'{prefix}WARNING: No labels found in {path}. See {HELP_URL}')\n",
    "        x['hash'] = get_hash(self.label_files + self.img_files)\n",
    "        x['results'] = nf, nm, ne, nc, len(self.img_files)\n",
    "        x['msgs'] = msgs  # warnings\n",
    "        x['version'] = 0.4  # cache version\n",
    "        try:\n",
    "            np.save(path, x)  # save cache for next time\n",
    "            path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix\n",
    "            logging.info(f'{prefix}New cache created: {path}')\n",
    "        except Exception as e:\n",
    "            logging.info(f'{prefix}WARNING: Cache directory {path.parent} is not writeable: {e}')  # path not writeable\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    # def __iter__(self):\n",
    "    #     self.count = -1\n",
    "    #     print('ran dataset iter')\n",
    "    #     #self.shuffled_vector = np.random.permutation(self.nF) if self.augment else np.arange(self.nF)\n",
    "    #     return self\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indices[index]  # linear, shuffled, or image_weights\n",
    "\n",
    "        hyp = self.hyp\n",
    "        mosaic = self.mosaic and random.random() < hyp['mosaic']\n",
    "        if mosaic:\n",
    "            # Load mosaic\n",
    "            img, labels = load_mosaic(self, index)\n",
    "            shapes = None\n",
    "\n",
    "            # MixUp augmentation\n",
    "            if random.random() < hyp['mixup']:\n",
    "                img, labels = mixup(img, labels, *load_mosaic(self, random.randint(0, self.n - 1)))\n",
    "\n",
    "        else:\n",
    "            # Load image\n",
    "            img, (h0, w0), (h, w) = load_image(self, index)\n",
    "\n",
    "            # Letterbox\n",
    "            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape\n",
    "            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\n",
    "            shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling\n",
    "\n",
    "            labels = self.labels[index].copy()\n",
    "            if labels.size:  # normalized xywh to pixel xyxy format\n",
    "                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])\n",
    "\n",
    "            if self.augment:\n",
    "                img, labels = random_perspective(img, labels,\n",
    "                                                 degrees=hyp['degrees'],\n",
    "                                                 translate=hyp['translate'],\n",
    "                                                 scale=hyp['scale'],\n",
    "                                                 shear=hyp['shear'],\n",
    "                                                 perspective=hyp['perspective'])\n",
    "\n",
    "        nl = len(labels)  # number of labels\n",
    "        if nl:\n",
    "            labels[:, 1:5] = xyxy2xywhn(labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=True, eps=1E-3)\n",
    "\n",
    "        if self.augment:\n",
    "            # Albumentations\n",
    "            img, labels = self.albumentations(img, labels)\n",
    "            nl = len(labels) # update after albumentations\n",
    "\n",
    "            # HSV color-space\n",
    "            augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])\n",
    "\n",
    "            # Flip up-down\n",
    "            if random.random() < hyp['flipud']:\n",
    "                img = np.flipud(img)\n",
    "                if nl:\n",
    "                    labels[:, 2] = 1 - labels[:, 2]\n",
    "\n",
    "            # Flip left-right\n",
    "            if random.random() < hyp['fliplr']:\n",
    "                img = np.fliplr(img)\n",
    "                if nl:\n",
    "                    labels[:, 1] = 1 - labels[:, 1]\n",
    "\n",
    "            # Cutouts\n",
    "            # labels = cutout(img, labels, p=0.5)\n",
    "\n",
    "        labels_out = torch.zeros((nl, 6))\n",
    "        if nl:\n",
    "            labels_out[:, 1:] = torch.from_numpy(labels)\n",
    "\n",
    "        # Convert\n",
    "        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        return torch.from_numpy(img), labels_out, self.img_files[index], shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30449ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Scanning '/media/asad/ADAS_CV/datasets_Vegs/tomatoes/dataset_v4/tomatoes_dataset_yolo/train_tomatoe_small.cache' images and labels... 18 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 18/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels are [array([[          0,        0.26,        0.87,       0.184,         0.2],\n",
      "       [          0,       0.283,       0.695,       0.194,        0.18],\n",
      "       [          0,       0.265,       0.535,        0.19,       0.235],\n",
      "       [          0,       0.091,       0.734,       0.178,       0.217],\n",
      "       [          0,        0.07,       0.562,       0.136,       0.235],\n",
      "       [          0,       0.068,       0.349,       0.132,       0.212]], dtype=float32), array([[          0,       0.955,       0.946,       0.082,       0.098],\n",
      "       [          0,       0.988,        0.85,       0.024,        0.11],\n",
      "       [          0,       0.939,       0.836,       0.066,       0.092],\n",
      "       [          0,       0.558,       0.956,       0.044,       0.048],\n",
      "       [          0,       0.559,       0.899,       0.046,       0.052],\n",
      "       [          0,       0.545,       0.772,       0.042,       0.055],\n",
      "       [          0,       0.548,       0.826,       0.048,       0.058],\n",
      "       [          0,       0.881,       0.642,        0.09,         0.1]], dtype=float32), array([[          0,        0.06,       0.055,       0.052,       0.065],\n",
      "       [          0,       0.104,       0.039,       0.048,       0.068],\n",
      "       [          0,       0.738,       0.463,       0.052,       0.075],\n",
      "       [          0,       0.764,       0.409,       0.056,       0.072],\n",
      "       [          0,       0.766,       0.336,       0.056,       0.072],\n",
      "       [          0,       0.751,       0.254,        0.05,       0.077]], dtype=float32), array([[          0,       0.894,       0.527,       0.212,       0.194]], dtype=float32), array([[          0,       0.851,       0.843,       0.297,       0.314],\n",
      "       [          0,       0.542,       0.839,       0.095,       0.082],\n",
      "       [          0,       0.473,       0.702,       0.105,       0.084],\n",
      "       [          0,       0.455,       0.578,        0.11,         0.1]], dtype=float32), array([[          0,       0.916,       0.482,       0.168,       0.224],\n",
      "       [          0,        0.74,       0.335,         0.1,       0.078],\n",
      "       [          0,        0.73,       0.284,        0.07,       0.052],\n",
      "       [          0,        0.76,       0.408,       0.075,       0.052],\n",
      "       [          0,       0.758,       0.433,       0.045,        0.03],\n",
      "       [          0,       0.802,       0.459,        0.08,       0.066],\n",
      "       [          0,       0.969,       0.275,       0.062,        0.07],\n",
      "       [          0,       0.425,       0.773,        0.26,       0.234],\n",
      "       [          0,       0.215,       0.659,        0.24,       0.182],\n",
      "       [          0,       0.054,       0.607,       0.103,       0.078],\n",
      "       [          0,       0.062,       0.526,        0.12,       0.108],\n",
      "       [          0,       0.069,       0.392,       0.122,       0.116],\n",
      "       [          0,       0.081,       0.432,       0.083,       0.072]], dtype=float32), array([[          0,       0.869,         0.6,       0.263,       0.468],\n",
      "       [          0,       0.907,        0.26,       0.185,       0.488],\n",
      "       [          0,       0.927,       0.888,        0.13,       0.224]], dtype=float32), array([[          0,       0.274,       0.606,       0.296,       0.372],\n",
      "       [          0,       0.148,       0.695,       0.292,        0.37],\n",
      "       [          0,        0.27,       0.362,       0.252,       0.295],\n",
      "       [          0,       0.428,       0.177,       0.316,        0.35],\n",
      "       [          0,       0.082,       0.932,       0.156,       0.135],\n",
      "       [          0,       0.041,       0.446,       0.066,       0.103]], dtype=float32), array([[          0,       0.124,        0.74,       0.247,        0.52],\n",
      "       [          0,       0.799,        0.44,       0.203,         0.2],\n",
      "       [          0,       0.741,       0.273,       0.228,       0.214],\n",
      "       [          0,        0.68,       0.223,       0.255,       0.182],\n",
      "       [          0,       0.625,       0.097,       0.255,       0.194],\n",
      "       [          0,       0.424,       0.038,       0.212,       0.076]], dtype=float32), array([[          0,       0.185,       0.527,       0.245,       0.194]], dtype=float32), array([[          0,       0.066,       0.037,       0.128,       0.075],\n",
      "       [          0,       0.055,       0.165,        0.11,       0.125],\n",
      "       [          0,       0.228,       0.044,       0.072,       0.077],\n",
      "       [          0,         0.3,       0.074,        0.06,       0.077]], dtype=float32), array([[          0,       0.938,       0.742,       0.125,       0.166],\n",
      "       [          0,       0.917,       0.538,       0.166,       0.165],\n",
      "       [          0,       0.653,       0.832,       0.176,       0.161],\n",
      "       [          0,       0.627,        0.63,       0.185,       0.161],\n",
      "       [          0,       0.544,       0.388,       0.161,       0.118],\n",
      "       [          0,       0.472,       0.261,        0.15,       0.116],\n",
      "       [          0,       0.395,       0.121,       0.134,       0.115],\n",
      "       [          0,       0.516,       0.079,       0.109,       0.103],\n",
      "       [          0,       0.641,       0.232,       0.162,       0.159],\n",
      "       [          0,       0.725,       0.364,       0.178,       0.146],\n",
      "       [          0,       0.954,        0.97,       0.093,        0.06],\n",
      "       [          0,         0.9,       0.847,       0.103,        0.07],\n",
      "       [          0,       0.841,       0.931,       0.099,       0.127],\n",
      "       [          0,       0.743,       0.923,       0.122,         0.1],\n",
      "       [          0,       0.774,       0.719,       0.154,       0.125],\n",
      "       [          0,       0.811,       0.819,       0.097,        0.08],\n",
      "       [          0,       0.682,       0.567,        0.17,       0.156],\n",
      "       [          0,        0.59,       0.443,       0.123,       0.123],\n",
      "       [          0,       0.399,       0.627,       0.173,       0.167],\n",
      "       [          0,       0.367,       0.435,       0.144,       0.146],\n",
      "       [          0,       0.268,       0.658,       0.139,        0.16],\n",
      "       [          0,       0.452,       0.808,       0.155,       0.179],\n",
      "       [          0,       0.543,        0.93,       0.192,       0.139],\n",
      "       [          0,       0.158,       0.808,       0.164,       0.162],\n",
      "       [          0,       0.066,       0.619,       0.117,       0.187],\n",
      "       [          0,       0.069,       0.377,        0.13,       0.189],\n",
      "       [          0,       0.077,       0.145,       0.105,       0.094],\n",
      "       [          0,        0.11,       0.949,       0.152,       0.103],\n",
      "       [          0,       0.293,        0.96,        0.17,        0.08],\n",
      "       [          0,       0.134,       0.253,       0.148,       0.096],\n",
      "       [          0,       0.036,       0.514,       0.058,       0.063]], dtype=float32), array([[          0,       0.743,        0.45,       0.269,       0.303],\n",
      "       [          0,       0.539,       0.613,       0.262,       0.323],\n",
      "       [          0,       0.812,       0.746,       0.308,       0.333],\n",
      "       [          0,       0.072,       0.327,       0.144,       0.249],\n",
      "       [          0,       0.229,        0.43,       0.188,       0.204],\n",
      "       [          0,       0.245,       0.818,       0.303,       0.304],\n",
      "       [          0,       0.142,       0.943,       0.284,        0.11],\n",
      "       [          0,       0.083,       0.662,       0.155,       0.281],\n",
      "       [          0,       0.251,       0.594,       0.166,       0.165],\n",
      "       [          0,       0.374,       0.968,       0.144,       0.059],\n",
      "       [          0,       0.844,       0.227,       0.056,       0.064],\n",
      "       [          0,        0.39,       0.529,       0.152,       0.153],\n",
      "       [          0,       0.202,       0.648,       0.134,       0.132]], dtype=float32), array([[          0,       0.072,       0.608,       0.145,       0.168]], dtype=float32), array([[          0,       0.741,       0.973,       0.066,       0.055],\n",
      "       [          0,       0.505,       0.718,       0.146,       0.175],\n",
      "       [          0,       0.476,       0.522,       0.088,         0.1],\n",
      "       [          0,       0.498,       0.613,       0.084,        0.08],\n",
      "       [          0,       0.358,       0.554,       0.048,       0.068],\n",
      "       [          0,       0.899,       0.589,        0.07,       0.092],\n",
      "       [          0,       0.967,       0.541,       0.066,       0.103],\n",
      "       [          0,       0.964,       0.427,       0.072,       0.115],\n",
      "       [          0,        0.88,       0.487,        0.08,        0.11],\n",
      "       [          0,       0.661,        0.66,       0.146,       0.175]], dtype=float32), array([[          0,       0.176,       0.103,         0.2,       0.205]], dtype=float32), array([[          0,       0.104,        0.29,       0.193,       0.275],\n",
      "       [          0,       0.695,       0.757,       0.222,       0.276],\n",
      "       [          0,       0.864,       0.632,       0.222,       0.271],\n",
      "       [          0,       0.393,       0.651,       0.217,       0.288],\n",
      "       [          0,        0.19,       0.507,       0.201,       0.276],\n",
      "       [          0,       0.386,       0.381,       0.203,       0.271],\n",
      "       [          0,       0.333,       0.204,       0.184,       0.238],\n",
      "       [          0,       0.759,       0.423,       0.176,       0.248],\n",
      "       [          0,        0.59,        0.49,       0.214,       0.282],\n",
      "       [          0,       0.613,       0.106,       0.181,        0.19],\n",
      "       [          0,       0.198,       0.804,        0.24,       0.208],\n",
      "       [          0,       0.542,       0.269,       0.181,       0.203],\n",
      "       [          0,       0.398,       0.845,       0.157,       0.116],\n",
      "       [          0,       0.882,        0.29,       0.169,       0.206],\n",
      "       [          0,       0.723,       0.228,        0.18,       0.223],\n",
      "       [          0,       0.827,        0.84,       0.118,       0.121],\n",
      "       [          0,       0.538,       0.751,       0.132,       0.216],\n",
      "       [          0,       0.944,       0.493,       0.112,       0.349],\n",
      "       [          0,       0.936,       0.814,       0.125,       0.178],\n",
      "       [          0,       0.043,       0.716,       0.082,       0.357],\n",
      "       [          0,       0.839,       0.106,       0.128,       0.191],\n",
      "       [          0,       0.478,       0.185,       0.101,       0.105],\n",
      "       [          0,        0.08,       0.542,       0.102,       0.203],\n",
      "       [          0,       0.197,       0.113,       0.391,       0.223],\n",
      "       [          0,       0.028,       0.446,       0.057,       0.254],\n",
      "       [          0,       0.124,       0.722,       0.151,       0.159],\n",
      "       [          0,       0.975,       0.661,       0.049,       0.228],\n",
      "       [          0,       0.485,       0.878,       0.179,       0.056],\n",
      "       [          0,       0.203,       0.304,       0.071,       0.127],\n",
      "       [          0,       0.497,        0.05,       0.138,       0.098]], dtype=float32), array([[          0,       0.462,       0.218,       0.049,       0.044]], dtype=float32)]\n",
      "Shapes are [[        500         400]\n",
      " [        500         400]\n",
      " [        500         400]\n",
      " [        400         500]\n",
      " [        400         500]\n",
      " [        400         500]\n",
      " [        400         500]\n",
      " [        500         400]\n",
      " [        400         500]\n",
      " [        400         500]\n",
      " [        500         400]\n",
      " [       1000        1000]\n",
      " [       1024         891]\n",
      " [        400         500]\n",
      " [        500         400]\n",
      " [        500         400]\n",
      " [       1024         753]\n",
      " [       3262        2832]]\n",
      "Rect is True\n"
     ]
    }
   ],
   "source": [
    "dataset = LoadImagesAndLabels2(label_dir, augment=True, rect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8897daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmean_anchors(dataset='./data/coco128.yaml', n=9, img_size=640, thr=4.0, gen=1000, verbose=True,plot=True):\n",
    "    \"\"\" Creates kmeans-evolved anchors from training dataset\n",
    "\n",
    "        Arguments:\n",
    "            dataset: path to data.yaml, or a loaded dataset\n",
    "            n: number of anchors\n",
    "            img_size: image size used for training\n",
    "            thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0\n",
    "            gen: generations to evolve anchors using genetic algorithm\n",
    "            verbose: print all results\n",
    "\n",
    "        Return:\n",
    "            k: kmeans evolved anchors\n",
    "\n",
    "        Usage:\n",
    "            from utils.autoanchor import *; _ = kmean_anchors()\n",
    "    \"\"\"\n",
    "    from scipy.cluster.vq import kmeans\n",
    "\n",
    "    thr = 1. / thr\n",
    "    prefix = colorstr('autoanchor: ')\n",
    "\n",
    "    def metric(k, wh):  # compute metrics\n",
    "        r = wh[:, None] / k[None]\n",
    "        x = torch.min(r, 1. / r).min(2)[0]  # ratio metric\n",
    "        # x = wh_iou(wh, torch.tensor(k))  # iou metric\n",
    "        return x, x.max(1)[0]  # x, best_x\n",
    "\n",
    "    def anchor_fitness(k):  # mutation fitness\n",
    "        _, best = metric(torch.tensor(k, dtype=torch.float32), wh)\n",
    "        return (best * (best > thr).float()).mean()  # fitness\n",
    "\n",
    "    def print_results(k):\n",
    "        k = k[np.argsort(k.prod(1))]  # sort small to large\n",
    "        x, best = metric(k, wh0)\n",
    "        bpr, aat = (best > thr).float().mean(), (x > thr).float().mean() * n  # best possible recall, anch > thr\n",
    "        print(f'{prefix}thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr')\n",
    "        print(f'{prefix}n={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, '\n",
    "              f'past_thr={x[x > thr].mean():.3f}-mean: ', end='')\n",
    "        for i, x in enumerate(k):\n",
    "            print('%i,%i' % (round(x[0]), round(x[1])), end=',  ' if i < len(k) - 1 else '\\n')  # use in *.cfg\n",
    "        return k\n",
    "\n",
    "    if isinstance(dataset, str):  # *.yaml file\n",
    "        with open(dataset, errors='ignore') as f:\n",
    "            data_dict = yaml.safe_load(f)  # model dict\n",
    "        from utils.datasets import LoadImagesAndLabels\n",
    "        dataset = LoadImagesAndLabels(data_dict['train'], augment=True, rect=True)\n",
    "\n",
    "    # Get label wh\n",
    "    #shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n",
    "    shapes=dataset.shapes\n",
    "    wh0 = np.concatenate([l[:, 3:5] * s for s, l in zip(shapes, dataset.labels)])  # wh\n",
    "\n",
    "    # Filter\n",
    "    i = (wh0 < 3.0).any(1).sum()\n",
    "    if i:\n",
    "        print(f'{prefix}WARNING: Extremely small objects found. {i} of {len(wh0)} labels are < 3 pixels in size.')\n",
    "    wh = wh0[(wh0 >= 2.0).any(1)]  # filter > 2 pixels\n",
    "    # wh = wh * (np.random.rand(wh.shape[0], 1) * 0.9 + 0.1)  # multiply by random scale 0-1\n",
    "\n",
    "    # Kmeans calculation\n",
    "    print(f'{prefix}Running kmeans for {n} anchors on {len(wh)} points...')\n",
    "    s = wh.std(0)  # sigmas for whitening\n",
    "    k, dist = kmeans(wh / s, n, iter=30)  # points, mean distance\n",
    "    assert len(k) == n, print(f'{prefix}ERROR: scipy.cluster.vq.kmeans requested {n} points but returned only {len(k)}')\n",
    "    k *= s\n",
    "    wh = torch.tensor(wh, dtype=torch.float32)  # filtered\n",
    "    wh0 = torch.tensor(wh0, dtype=torch.float32)  # unfiltered\n",
    "    k = print_results(k)\n",
    "    \n",
    "    print(f\"Results before Evloution {k}\")\n",
    "\n",
    "    # Plot\n",
    "    # k, d = [None] * 20, [None] * 20\n",
    "    # for i in tqdm(range(1, 21)):\n",
    "    #     k[i-1], d[i-1] = kmeans(wh / s, i)  # points, mean distance\n",
    "    # fig, ax = plt.subplots(1, 2, figsize=(14, 7), tight_layout=True)\n",
    "    # ax = ax.ravel()\n",
    "    # ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.')\n",
    "    # fig, ax = plt.subplots(1, 2, figsize=(14, 7))  # plot wh\n",
    "    # ax[0].hist(wh[wh[:, 0]<100, 0],400)\n",
    "    # ax[1].hist(wh[wh[:, 1]<100, 1],400)\n",
    "    # fig.savefig('wh.png', dpi=200)\n",
    "\n",
    "    # Evolve\n",
    "    npr = np.random\n",
    "    f, sh, mp, s = anchor_fitness(k), k.shape, 0.9, 0.1  # fitness, generations, mutation prob, sigma\n",
    "    pbar = tqdm(range(gen), desc=f'{prefix}Evolving anchors with Genetic Algorithm:')  # progress bar\n",
    "    for _ in pbar:\n",
    "        v = np.ones(sh)\n",
    "        while (v == 1).all():  # mutate until a change occurs (prevent duplicates)\n",
    "            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n",
    "        kg = (k.copy() * v).clip(min=2.0)\n",
    "        fg = anchor_fitness(kg)\n",
    "        if fg > f:\n",
    "            f, k = fg, kg.copy()\n",
    "            pbar.desc = f'{prefix}Evolving anchors with Genetic Algorithm: fitness = {f:.4f}'\n",
    "            if verbose:\n",
    "                print_results(k)\n",
    "    if plot:\n",
    "        whpl=wh.cpu().numpy()\n",
    "        plt.scatter(whpl[:, 0], whpl[:, 1])\n",
    "        plt.scatter(k[:, 0], k[:, 1], c='r')\n",
    "        plt.xlabel(\"Widths\")\n",
    "        plt.ylabel(\"Heights\")\n",
    "    \n",
    "    return print_results(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a92c926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 3 anchors on 145 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.472/0.738-mean/best, past_thr=0.573-mean: 37,36,  109,100,  181,187\n",
      "Results before Evloution [[     37.026      36.246]\n",
      " [     108.58      100.39]\n",
      " [     181.43      186.74]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7537:  21%|██        | 210/1000 [00:00<00:00, 2096.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.473/0.738-mean/best, past_thr=0.574-mean: 37,36,  108,101,  179,186\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.20 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.472/0.739-mean/best, past_thr=0.576-mean: 36,37,  108,100,  179,186\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.19 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.473/0.740-mean/best, past_thr=0.579-mean: 37,36,  107,100,  177,183\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.19 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.472/0.741-mean/best, past_thr=0.578-mean: 35,36,  107,100,  177,183\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.19 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.473/0.741-mean/best, past_thr=0.579-mean: 36,36,  108,101,  178,181\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.20 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.470/0.742-mean/best, past_thr=0.575-mean: 34,34,  98,103,  178,176\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.20 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.747-mean/best, past_thr=0.584-mean: 33,35,  102,103,  168,164\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.20 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.747-mean/best, past_thr=0.583-mean: 33,34,  101,102,  171,162\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.20 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.748-mean/best, past_thr=0.585-mean: 33,34,  101,102,  169,161\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.20 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.748-mean/best, past_thr=0.584-mean: 33,34,  102,102,  171,161\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.749-mean/best, past_thr=0.582-mean: 33,34,  99,100,  168,160\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.750-mean/best, past_thr=0.583-mean: 34,34,  101,98,  163,164\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.750-mean/best, past_thr=0.583-mean: 34,33,  102,95,  163,164\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.752-mean/best, past_thr=0.583-mean: 33,34,  102,94,  165,162\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.752-mean/best, past_thr=0.583-mean: 33,34,  102,93,  165,161\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.752-mean/best, past_thr=0.581-mean: 34,35,  101,91,  163,164\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.753-mean/best, past_thr=0.582-mean: 34,35,  100,92,  164,164\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.753-mean/best, past_thr=0.582-mean: 34,35,  100,92,  164,164\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.23 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.753-mean/best, past_thr=0.580-mean: 34,35,  101,91,  165,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.23 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.480/0.753-mean/best, past_thr=0.580-mean: 34,35,  101,92,  165,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.24 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.480/0.753-mean/best, past_thr=0.580-mean: 34,35,  97,93,  166,157\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.23 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.753-mean/best, past_thr=0.579-mean: 34,34,  97,91,  166,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.753-mean/best, past_thr=0.573-mean: 34,35,  93,86,  170,156\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.754-mean/best, past_thr=0.573-mean: 34,36,  95,86,  167,158\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.476/0.754-mean/best, past_thr=0.571-mean: 34,35,  94,84,  167,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.25 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.476/0.754-mean/best, past_thr=0.573-mean: 34,35,  94,85,  167,160\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.25 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.476/0.754-mean/best, past_thr=0.573-mean: 34,35,  94,85,  167,160\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.754-mean/best, past_thr=0.574-mean: 34,35,  94,87,  164,157\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.754-mean/best, past_thr=0.573-mean: 34,35,  94,86,  165,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.754-mean/best, past_thr=0.573-mean: 34,35,  94,87,  164,158\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.477/0.754-mean/best, past_thr=0.573-mean: 34,35,  94,87,  164,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.754-mean/best, past_thr=0.576-mean: 34,35,  94,88,  164,156\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.754-mean/best, past_thr=0.575-mean: 34,35,  94,88,  165,156\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.754-mean/best, past_thr=0.574-mean: 34,35,  93,88,  165,157\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.755-mean/best, past_thr=0.574-mean: 34,35,  93,88,  165,158\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.755-mean/best, past_thr=0.574-mean: 34,35,  93,88,  165,158\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.755-mean/best, past_thr=0.575-mean: 34,35,  93,88,  165,159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7547: 100%|██████████| 1000/1000 [00:00<00:00, 3375.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.755-mean/best, past_thr=0.575-mean: 34,35,  93,88,  165,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.755-mean/best, past_thr=0.575-mean: 34,35,  93,88,  165,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.755-mean/best, past_thr=0.575-mean: 34,35,  93,88,  165,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.755-mean/best, past_thr=0.575-mean: 34,35,  93,88,  165,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.479/0.755-mean/best, past_thr=0.575-mean: 34,35,  93,88,  165,159\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.24 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.755-mean/best, past_thr=0.577-mean: 34,35,  93,88,  165,160\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 2.24 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=3, img_size=640, metric_all=0.478/0.755-mean/best, past_thr=0.577-mean: 34,35,  93,88,  165,160\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k=kmean_anchors(dataset,n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43297186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1.0302,     0.94861,     0.97167])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[:,1]/k[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bd762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
